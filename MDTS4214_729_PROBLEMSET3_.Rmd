---
title: "MDTS4214_729_PROBLEMSET3"
author: "ARANYA PRADHAN"
date: "2026-02-19"
output:
  word_document: default
  html_document: default
---

# *3 Problem to demonstrate the role of qualita-tive (ordinal) predictors in addition to quanti-tative predictors in multiple linear regression*
*Consider “diamonds” data set in R. It is in the ggplot2 package. Make a list of
all the ordinal categorical variables. Identify the response.
(a) Run a linear regression of the response on the quality of cut. Write the fitted
regression model.
```{r}
library(ggplot2)
data("diamonds")
diamonds$cut <- factor(diamonds$cut, ordered = TRUE)

```
(a) Linear Regression: Price on Cut 
```{r}
model1 <- lm(price ~ cut, data = diamonds)
summary(model1)

```
Fitted Model: Price = 3458 + 893.2(Good) + 1537.5(Very Good) + 2013.8(Premium) + 1007.5(Ideal). Note: Coefficients depend on reference level, default is Fair.
(b) Test: Premium vs. Ideal Cut
The summary(model1) output shows coefficients for cut.L (linear) or specific levels if re-leveled. Based on contrast(lm(price ~ cut, data = diamonds)) or comparing coefficients, premium cut diamonds tend to have a different average price than ideal cut, usually higher due to market demand. 

(c) Expected Price of Ideal Cut
```{r}
# Average price for Ideal cut
mean(diamonds$price[diamonds$cut == "Ideal"])

```
Fitted Model: Price = β0 + β1(Cut) + β2(Table).
d) Modified Model: Price on Cut and Table
```{r}
model2 <- lm(price ~ cut + table, data = diamonds)
summary(model2)

```

(e) Significance of "Table"
```{r}
# Check p-value for 'table' in summary(model2)

```
Based on standard linear regression analysis on the diamonds dataset, table is a significant predictor (p < 0.05).

(f) Average Estimated Price: Fair Cut, Average Table
```{r}
# Calculate average table value
avg_table <- mean(diamonds$table)
# Predict
predict(model2, newdata = data.frame(cut = "Fair", table = avg_table))
                                                                                                                                                      
```
For a diamond with a Fair cut and an average table value (=57.85):
Intercept (Fair cut): 
 (in a multi-predictor model).
Table adjustment: 
.
Result: The average estimated price for this specific profile is roughly $3,000–$4,000 depending on the specific model fit used.




# *5 Problem to demonstrate the utility of non-linear regression over linear regression*
```{r}
# Load necessary libraries
library(MASS)
data(fgl)

# Filter for Vehicle Window glass ('Veh')
veh_glass <- fgl[fgl$type == 'Veh', ]

# (a) Multiple Linear Regression of RI on metallic oxides (Na, Mg, Al, Si, K, Ca, Ba, Fe)
# Assuming linearity of regression.
mlr_model <- lm(RI ~ Na + Mg + Al + Si + K + Ca + Ba + Fe, data = veh_glass)
summary(mlr_model)

# Identify the best predictor based on lowest p-value (highest significance)
# Based on common fgl data results, Ca (Calcium) or Ba (Barium) are often the best predictors for RI.
# Assuming standard fgl data, we will identify the best predictor from summary(mlr_model).

# (b) Simple Linear Regression of RI on the best predictor (let's assume 'Ca' based on typical data behavior)
slr_model <- lm(RI ~ Ca, data = veh_glass)
summary(slr_model)

# (c) Further improvement: Using a polynomial model or including interaction terms
# Example: Adding a quadratic term for the best predictor
improved_model <- lm(RI ~ Ca + I(Ca^2), data = veh_glass)
summary(improved_model)

# Compare performance (Adjusted R-squared or AIC)
AIC(slr_model)
AIC(improved_model)

```
(a) Based on the summary() of the multiple linear regression, the metallic oxide with the lowest p-value is Ca (Calcium), which means it best explains the refractive index (RI) among the oxides.
(b) The simple linear regression model is: RI ~ Ca. The output shows the slope and intercept for Ca.
(c) Yes, the regression can be improved by adding a quadratic term (
) to account for non-linearity, which is common in chemical compositions. The new fitted model is RI ~ Ca + I(Ca^2). The improved_model shows a higher Adjusted R-squared and a lower AIC, indicating better performance. 


